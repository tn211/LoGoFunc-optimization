{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, ast, json, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, matthews_corrcoef\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import  RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGONE_FEATURES: ['feature487', 'feature489', 'feature491', 'feature492', 'feature493', 'feature494', 'feature495', 'feature496', 'feature497', 'feature498', 'feature499', 'feature458', 'feature4', 'feature6', 'feature10', 'feature13', 'feature31', 'feature35', 'feature36', 'feature46', 'feature47', 'feature48', 'feature49', 'feature45', 'feature50', 'feature51', 'feature52', 'feature53', 'feature54', 'feature55', 'feature56', 'feature57', 'feature58', 'feature59', 'feature60', 'feature61', 'feature62', 'feature63', 'feature64', 'feature65', 'feature66', 'feature67', 'feature68', 'feature69', 'feature70', 'feature71', 'feature72', 'feature73', 'feature74', 'feature75', 'feature76', 'feature77', 'feature84', 'feature85', 'feature86', 'feature87', 'feature88', 'feature89', 'feature90', 'feature91', 'feature92', 'feature93', 'feature94', 'feature95', 'feature96', 'feature97', 'feature98', 'feature99', 'feature100', 'feature101', 'feature102', 'feature103', 'feature105', 'feature107', 'feature108', 'feature109', 'feature110', 'feature111', 'feature112', 'feature113', 'feature114', 'feature115', 'feature116', 'feature117', 'feature118', 'feature119', 'feature120', 'feature121', 'feature122', 'feature123', 'feature124', 'feature125', 'feature126', 'feature127', 'feature128', 'feature129', 'feature130', 'feature131', 'feature132', 'feature133', 'feature134', 'feature135', 'feature136', 'feature137', 'feature138', 'feature139', 'feature140', 'feature141', 'feature142', 'feature143', 'feature144', 'feature145', 'feature146', 'feature147', 'feature148', 'feature149', 'feature150', 'feature151', 'feature152', 'feature153', 'feature154', 'feature155', 'feature156', 'feature157', 'feature158', 'feature159', 'feature160', 'feature161', 'feature162', 'feature163', 'feature164', 'feature165', 'feature166', 'feature167', 'feature168', 'feature169', 'feature170', 'feature171', 'feature172', 'feature173', 'feature174', 'feature175', 'feature176', 'feature177', 'feature178', 'feature179', 'feature180', 'feature181', 'feature182', 'feature183', 'feature184', 'feature185', 'feature186', 'feature187', 'feature188', 'feature189', 'feature190', 'feature191', 'feature192', 'feature193', 'feature194', 'feature195', 'feature196', 'feature197', 'feature198', 'feature199', 'feature200', 'feature201', 'feature202', 'feature203', 'feature204', 'feature205', 'feature206', 'feature207', 'feature208', 'feature209', 'feature210', 'feature211', 'feature212', 'feature213', 'feature214', 'feature215', 'feature216', 'feature217', 'feature218', 'feature219', 'feature220', 'feature221', 'feature222', 'feature223', 'feature224', 'feature225', 'feature226', 'feature227', 'feature228', 'feature229', 'feature230', 'feature231', 'feature232', 'feature233', 'feature234', 'feature235', 'feature236', 'feature237', 'feature238', 'feature239', 'feature240', 'feature241', 'feature242', 'feature243', 'feature244', 'feature245', 'feature246', 'feature247', 'feature248', 'feature249', 'feature250', 'feature251', 'feature252', 'feature253', 'feature254', 'feature255', 'feature256', 'feature257', 'feature258', 'feature259', 'feature260', 'feature261', 'feature262', 'feature263', 'feature264', 'feature265', 'feature266', 'feature267', 'feature268', 'feature269', 'feature270', 'feature271', 'feature272', 'feature273', 'feature274', 'feature275', 'feature276', 'feature277', 'feature278', 'feature279', 'feature280', 'feature281', 'feature282', 'feature283', 'feature284', 'feature285', 'feature286', 'feature287', 'feature288', 'feature289', 'feature290', 'feature291', 'feature292', 'feature293', 'feature294', 'feature295', 'feature296', 'feature297', 'feature298', 'feature299', 'feature300', 'feature301', 'feature302', 'feature303', 'feature304', 'feature305', 'feature306', 'feature307', 'feature308', 'feature309', 'feature310', 'feature311', 'feature312', 'feature313', 'feature314', 'feature315', 'feature316', 'feature317', 'feature318', 'feature319', 'feature320', 'feature321', 'feature322', 'feature323', 'feature324', 'feature325', 'feature326', 'feature327', 'feature328', 'feature329', 'feature330', 'feature331', 'feature332', 'feature333', 'feature334', 'feature335', 'feature336', 'feature337', 'feature338', 'feature339', 'feature340', 'feature341', 'feature342', 'feature343', 'feature344', 'feature345', 'feature346', 'feature347', 'feature348', 'feature349', 'feature355', 'feature356', 'feature357', 'feature358', 'feature359', 'feature360', 'feature361', 'feature362', 'feature363', 'feature364', 'feature365', 'feature366', 'feature367', 'feature368', 'feature369', 'feature373', 'feature374', 'feature375', 'feature376', 'feature421', 'feature422', 'feature423', 'feature424', 'feature425', 'feature426', 'feature427', 'feature428', 'feature429', 'feature430', 'feature431', 'feature432', 'feature433', 'feature434', 'feature435', 'feature436', 'feature437', 'feature438', 'feature439', 'feature440', 'feature441', 'feature442', 'feature443', 'feature444', 'feature445', 'feature446', 'feature447', 'feature448', 'feature459', 'feature460', 'feature461', 'feature462', 'feature463', 'feature464', 'feature465', 'feature466', 'feature467', 'feature471', 'feature472', 'feature473', 'feature474', 'feature475', 'feature476', 'feature477', 'feature478', 'feature479', 'feature480', 'feature481', 'feature482', 'feature483', 'feature484', 'feature485', 'feature486']\n",
      "MEDIAN_FEATURES: ['feature3', 'feature5', 'feature7', 'feature8', 'feature9', 'feature11', 'feature12', 'feature14', 'feature15', 'feature16', 'feature17', 'feature18', 'feature19', 'feature20', 'feature21', 'feature22', 'feature23', 'feature24', 'feature25', 'feature26', 'feature27', 'feature28', 'feature29', 'feature30', 'feature32', 'feature33', 'feature34', 'feature37', 'feature38', 'feature39', 'feature40', 'feature41', 'feature42', 'feature43', 'feature79', 'feature80', 'feature81', 'feature82', 'feature350', 'feature351', 'feature352', 'feature353', 'feature354', 'feature370', 'feature371', 'feature372', 'feature378', 'feature379', 'feature380', 'feature381', 'feature382', 'feature383', 'feature384', 'feature385', 'feature386', 'feature387', 'feature388', 'feature389', 'feature390', 'feature391', 'feature392', 'feature393', 'feature394', 'feature395', 'feature396', 'feature397', 'feature398', 'feature399', 'feature400', 'feature401', 'feature402', 'feature403', 'feature404', 'feature405', 'feature406', 'feature407', 'feature408', 'feature409', 'feature410', 'feature411', 'feature412', 'feature413', 'feature414', 'feature415', 'feature416', 'feature417', 'feature418', 'feature419', 'feature420', 'feature449', 'feature450', 'feature451', 'feature452', 'feature453', 'feature454', 'feature455', 'feature456', 'feature457', 'feature469', 'feature470']\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/negone_median.json'\n",
    "\n",
    "# Read the JSON.\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the lists.\n",
    "negone_features = data.get('NEGONE_FEATURES', [])\n",
    "median_features = data.get('MEDIAN_FEATURES', [])\n",
    "print('NEGONE_FEATURES:', negone_features)\n",
    "print('MEDIAN_FEATURES:', median_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keys: [35, 36, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]\n",
      "Length: 26\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/patterns.json'\n",
    "\n",
    "# Read the JSON.\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract keys and convert to integer numbers.\n",
    "keys_list = [int(key.replace('feature', '')) for key in data.keys()]\n",
    "drop_numbers = keys_list\n",
    "print('Extracted Keys:', drop_numbers)\n",
    "print('Length:', len(drop_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveBeforeAfterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.drop_cols = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(X.shape)\n",
    "        self.drop_cols = [col for col in X.columns if any(f'feature{num}' == col for num in drop_numbers)]\n",
    "        print(f\"Columns to be dropped: {self.drop_cols}\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(f\"Columns being dropped: {[col for col in self.drop_cols if col in X.columns]}\")\n",
    "        X = X.drop(columns=self.drop_cols, errors='ignore')\n",
    "        print(X.shape)\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [f for f in input_features if f not in self.drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(preprocessor, train_data, train_labels, quiet=False):\n",
    "    for k, v in preprocessor.steps:\n",
    "        print(f\"Applying step: {k}\")\n",
    "        print(f\"Input shape: {train_data.shape}\")\n",
    "        print(f\"Input columns: {train_data.columns}\")\n",
    "        \n",
    "        if k == 'initial':\n",
    "            start = time.time()\n",
    "            v.fit(train_data)\n",
    "            train_data = pd.DataFrame(v.transform(train_data), columns=v.get_feature_names_out())\n",
    "            end = time.time()\n",
    "            if not quiet:\n",
    "                print(k + ' took ' + str(end - start) + ' to run.')\n",
    "        elif k == 'oversampling' or k == 'undersampling':\n",
    "            start = time.time()\n",
    "            input_features = train_data.columns\n",
    "            train_data, train_labels = v.fit_resample(train_data, train_labels)\n",
    "            train_data = pd.DataFrame(train_data, columns=input_features)\n",
    "            end = time.time()\n",
    "            if not quiet:\n",
    "                print(k + ' took ' + str(end - start) + ' to run.')\n",
    "        else:\n",
    "            start = time.time()\n",
    "            v.fit(train_data)\n",
    "            input_features = train_data.columns\n",
    "            train_data = pd.DataFrame(v.transform(train_data), columns=v.get_feature_names_out(input_features))\n",
    "            end = time.time()\n",
    "            if not quiet:\n",
    "                print(k + ' took ' + str(end - start) + ' to run.')\n",
    "        \n",
    "        print(f\"Output shape: {train_data.shape}\")\n",
    "        print(f\"Output columns: {train_data.columns}\")\n",
    "        print(\"---\")\n",
    "\n",
    "    for col in train_data.columns:\n",
    "        try:\n",
    "            train_data[col] = train_data[col].astype('float')\n",
    "        except:\n",
    "            train_data[col] = train_data[col].astype('category')\n",
    "\n",
    "    return train_data, train_labels\n",
    "\n",
    "def transform(test_data, preprocessor, quiet=False):\n",
    "    for k, v in preprocessor.steps:\n",
    "        if k == 'initial':\n",
    "            test_data = pd.DataFrame(v.transform(test_data), columns=v.get_feature_names_out())\n",
    "        elif k == 'oversampling' or k == 'undersampling':\n",
    "            continue\n",
    "        else:\n",
    "            test_data = v.transform(test_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "\n",
    "    for col in test_data.columns:\n",
    "        try:\n",
    "            test_data[col] = test_data[col].astype('float')\n",
    "        except:\n",
    "            test_data[col] = test_data[col].astype('category')\n",
    "\n",
    "    return test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the soft-voting function used to aggregate the predictions.\n",
    "def soft_vote(preds):\n",
    "    summed_preds = [[np.sum(preds[:, j][:, i]) for i in range(3)] for j in range(len(preds[0]))]\n",
    "    return [softmax(np.log(sp)) for sp in summed_preds]\n",
    "\n",
    "# This is used to drop columns that only contain NaN values.\n",
    "def drop_allnan(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].isna().sum() == len(data):\n",
    "            data = data.drop(columns=col)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 500\n",
      "Shape of data: (2831, 500)\n",
      "Shape of X_train: (25546, 500)\n",
      "Filtered NEGONE_FEATURES: ['feature487', 'feature489', 'feature491', 'feature492', 'feature493', 'feature494', 'feature495', 'feature496', 'feature497', 'feature498', 'feature499', 'feature458', 'feature4', 'feature6', 'feature10', 'feature13', 'feature31', 'feature35', 'feature36', 'feature46', 'feature47', 'feature48', 'feature49', 'feature45', 'feature50', 'feature51', 'feature52', 'feature53', 'feature54', 'feature55', 'feature56', 'feature57', 'feature58', 'feature59', 'feature60', 'feature61', 'feature62', 'feature63', 'feature64', 'feature65', 'feature66', 'feature67', 'feature68', 'feature69', 'feature70', 'feature71', 'feature72', 'feature73', 'feature74', 'feature75', 'feature76', 'feature77', 'feature84', 'feature85', 'feature86', 'feature87', 'feature88', 'feature89', 'feature90', 'feature91', 'feature92', 'feature93', 'feature94', 'feature95', 'feature96', 'feature97', 'feature98', 'feature99', 'feature100', 'feature101', 'feature102', 'feature103', 'feature105', 'feature107', 'feature108', 'feature109', 'feature110', 'feature111', 'feature112', 'feature113', 'feature114', 'feature115', 'feature116', 'feature117', 'feature118', 'feature119', 'feature120', 'feature121', 'feature122', 'feature123', 'feature124', 'feature125', 'feature126', 'feature127', 'feature128', 'feature129', 'feature130', 'feature131', 'feature132', 'feature133', 'feature134', 'feature135', 'feature136', 'feature137', 'feature138', 'feature139', 'feature140', 'feature141', 'feature142', 'feature143', 'feature144', 'feature145', 'feature146', 'feature147', 'feature148', 'feature149', 'feature150', 'feature151', 'feature152', 'feature153', 'feature154', 'feature155', 'feature156', 'feature157', 'feature158', 'feature159', 'feature160', 'feature161', 'feature162', 'feature163', 'feature164', 'feature165', 'feature166', 'feature167', 'feature168', 'feature169', 'feature170', 'feature171', 'feature172', 'feature173', 'feature174', 'feature175', 'feature176', 'feature177', 'feature178', 'feature179', 'feature180', 'feature181', 'feature182', 'feature183', 'feature184', 'feature185', 'feature186', 'feature187', 'feature188', 'feature189', 'feature190', 'feature191', 'feature192', 'feature193', 'feature194', 'feature195', 'feature196', 'feature197', 'feature198', 'feature199', 'feature200', 'feature201', 'feature202', 'feature203', 'feature204', 'feature205', 'feature206', 'feature207', 'feature208', 'feature209', 'feature210', 'feature211', 'feature212', 'feature213', 'feature214', 'feature215', 'feature216', 'feature217', 'feature218', 'feature219', 'feature220', 'feature221', 'feature222', 'feature223', 'feature224', 'feature225', 'feature226', 'feature227', 'feature228', 'feature229', 'feature230', 'feature231', 'feature232', 'feature233', 'feature234', 'feature235', 'feature236', 'feature237', 'feature238', 'feature239', 'feature240', 'feature241', 'feature242', 'feature243', 'feature244', 'feature245', 'feature246', 'feature247', 'feature248', 'feature249', 'feature250', 'feature251', 'feature252', 'feature253', 'feature254', 'feature255', 'feature256', 'feature257', 'feature258', 'feature259', 'feature260', 'feature261', 'feature262', 'feature263', 'feature264', 'feature265', 'feature266', 'feature267', 'feature268', 'feature269', 'feature270', 'feature271', 'feature272', 'feature273', 'feature274', 'feature275', 'feature276', 'feature277', 'feature278', 'feature279', 'feature280', 'feature281', 'feature282', 'feature283', 'feature284', 'feature285', 'feature286', 'feature287', 'feature288', 'feature289', 'feature290', 'feature291', 'feature292', 'feature293', 'feature294', 'feature295', 'feature296', 'feature297', 'feature298', 'feature299', 'feature300', 'feature301', 'feature302', 'feature303', 'feature304', 'feature305', 'feature306', 'feature307', 'feature308', 'feature309', 'feature310', 'feature311', 'feature312', 'feature313', 'feature314', 'feature315', 'feature316', 'feature317', 'feature318', 'feature319', 'feature320', 'feature321', 'feature322', 'feature323', 'feature324', 'feature325', 'feature326', 'feature327', 'feature328', 'feature329', 'feature330', 'feature331', 'feature332', 'feature333', 'feature334', 'feature335', 'feature336', 'feature337', 'feature338', 'feature339', 'feature340', 'feature341', 'feature342', 'feature343', 'feature344', 'feature345', 'feature346', 'feature347', 'feature348', 'feature349', 'feature355', 'feature356', 'feature357', 'feature358', 'feature359', 'feature360', 'feature361', 'feature362', 'feature363', 'feature364', 'feature365', 'feature366', 'feature367', 'feature368', 'feature369', 'feature373', 'feature374', 'feature375', 'feature376', 'feature421', 'feature422', 'feature423', 'feature424', 'feature425', 'feature426', 'feature427', 'feature428', 'feature429', 'feature430', 'feature431', 'feature432', 'feature433', 'feature434', 'feature435', 'feature436', 'feature437', 'feature438', 'feature439', 'feature440', 'feature441', 'feature442', 'feature443', 'feature444', 'feature445', 'feature446', 'feature447', 'feature448', 'feature459', 'feature460', 'feature461', 'feature462', 'feature463', 'feature464', 'feature465', 'feature466', 'feature467', 'feature471', 'feature472', 'feature473', 'feature474', 'feature475', 'feature476', 'feature477', 'feature478', 'feature479', 'feature480', 'feature481', 'feature482', 'feature483', 'feature484', 'feature485', 'feature486']\n",
      "Filtered MEDIAN_FEATURES: ['feature3', 'feature5', 'feature7', 'feature8', 'feature9', 'feature11', 'feature12', 'feature14', 'feature15', 'feature16', 'feature17', 'feature18', 'feature19', 'feature20', 'feature21', 'feature22', 'feature23', 'feature24', 'feature25', 'feature26', 'feature27', 'feature28', 'feature29', 'feature30', 'feature32', 'feature33', 'feature34', 'feature37', 'feature38', 'feature39', 'feature40', 'feature41', 'feature42', 'feature43', 'feature79', 'feature80', 'feature81', 'feature82', 'feature350', 'feature351', 'feature352', 'feature353', 'feature354', 'feature370', 'feature371', 'feature372', 'feature378', 'feature379', 'feature380', 'feature381', 'feature382', 'feature383', 'feature384', 'feature385', 'feature386', 'feature387', 'feature388', 'feature389', 'feature390', 'feature391', 'feature392', 'feature393', 'feature394', 'feature395', 'feature396', 'feature397', 'feature398', 'feature399', 'feature400', 'feature401', 'feature402', 'feature403', 'feature404', 'feature405', 'feature406', 'feature407', 'feature408', 'feature409', 'feature410', 'feature411', 'feature412', 'feature413', 'feature414', 'feature415', 'feature416', 'feature417', 'feature418', 'feature419', 'feature420', 'feature449', 'feature450', 'feature451', 'feature452', 'feature453', 'feature454', 'feature455', 'feature456', 'feature457', 'feature469', 'feature470']\n",
      "['feature0', 'feature35', 'feature95', 'feature351', 'feature453', 'feature458', 'feature10', 'feature93', 'feature492', 'feature97', 'feature60', 'feature404', 'feature66', 'feature67', 'feature498', 'feature101', 'feature96', 'feature92', 'feature88', 'feature36', 'feature68', 'feature499', 'feature99', 'feature460', 'feature489', 'feature493', 'feature77', 'feature495', 'feature65', 'feature64', 'feature31', 'feature32', 'feature455', 'feature456', 'feature85', 'feature87', 'feature451', 'feature135', 'feature55', 'feature59', 'feature231', 'feature4', 'feature71', 'feature78', 'feature452', 'feature94', 'feature76', 'feature75', 'feature126', 'feature401', 'feature414', 'feature413', 'feature102', 'feature405', 'feature98', 'feature412', 'feature415', 'feature147', 'feature13', 'feature385', 'feature410', 'feature104', 'feature420', 'feature74', 'feature122', 'feature100', 'feature497', 'feature180', 'feature133', 'feature144', 'feature112', 'feature120', 'feature89', 'feature136', 'feature131', 'feature163', 'feature110', 'feature237', 'feature396', 'feature399', 'feature73', 'feature454', 'feature457', 'feature469', 'feature289', 'feature470', 'feature236', 'feature228', 'feature491', 'feature70', 'feature494', 'feature114', 'feature409', 'feature487', 'feature121', 'feature418', 'feature124', 'feature449', 'feature422', 'feature119', 'feature210', 'feature408', 'feature394', 'feature389', 'feature375', 'feature326', 'feature298', 'feature281', 'feature262', 'feature241', 'feature140', 'feature219', 'feature184', 'feature192', 'feature411', 'feature118', 'feature1', 'feature52', 'feature53', 'feature111', 'feature90', 'feature91', 'feature61', 'feature58', 'feature84', 'feature388', 'feature50', 'feature179', 'feature421', 'feature450', 'feature72', 'feature56', 'feature313', 'feature160', 'feature161', 'feature406', 'feature116', 'feature392', 'feature391', 'feature309', 'feature322', 'feature21', 'feature238', 'feature276', 'feature115', 'feature113', 'feature395', 'feature188', 'feature301', 'feature496', 'feature6', 'feature127', 'feature329', 'feature142', 'feature129', 'feature386', 'feature387', 'feature259', 'feature447', 'feature279', 'feature330', 'feature254', 'feature390', 'feature419', 'feature216', 'feature437', 'feature200', 'feature211', 'feature294', 'feature195', 'feature28', 'feature398', 'feature269', 'feature267', 'feature266', 'feature263', 'feature261', 'feature260', 'feature256', 'feature402', 'feature246', 'feature244', 'feature393', 'feature57', 'feature240', 'feature283', 'feature438', 'feature234', 'feature63', 'feature226', 'feature69', 'feature440', 'feature274', 'feature139', 'feature86', 'feature189', 'feature168', 'feature380', 'feature185', 'feature123', 'feature7', 'feature128', 'feature314', 'feature152', 'feature169', 'feature183', 'feature176', 'feature305', 'feature146', 'feature323', 'feature243', 'feature324', 'feature365', 'feature318', 'feature14', 'feature245', 'feature248', 'feature300', 'feature251', 'feature280', 'feature235', 'feature483', 'feature484', 'feature278', 'feature258', 'feature355', 'feature332', 'feature333', 'feature264', 'feature268', 'feature270', 'feature109', 'feature403', 'feature372', 'feature233', 'feature232', 'feature194', 'feature196', 'feature381', 'feature436', 'feature304', 'feature297', 'feature202', 'feature429', 'feature181', 'feature448', 'feature306', 'feature174', 'feature299', 'feature417', 'feature172', 'feature250', 'feature416', 'feature22', 'feature62', 'feature29', 'feature230', 'feature284', 'feature286', 'feature312', 'feature311', 'feature164', 'feature45', 'feature339', 'feature321', 'feature335', 'feature277', 'feature296', 'feature362', 'feature287', 'feature292', 'feature327', 'feature307', 'feature357', 'feature290', 'feature229', 'feature166', 'feature187', 'feature103', 'feature186', 'feature445', 'feature24', 'feature173', 'feature171', 'feature44', 'feature20', 'feature19', 'feature162', 'feature459', 'feature480', 'feature143', 'feature479', 'feature157', 'feature155', 'feature12', 'feature153', 'feature474', 'feature198', 'feature441', 'feature204', 'feature252', 'feature225', 'feature201', 'feature30', 'feature221', 'feature218', 'feature108', 'feature213', 'feature26', 'feature130', 'feature257', 'feature8', 'feature54', 'feature255', 'feature242', 'feature478', 'feature349', 'feature348', 'feature482', 'feature49', 'feature352', 'feature486', 'feature347', 'feature473', 'feature400', 'feature471', 'feature41', 'feature40', 'feature346', 'feature407', 'feature25', 'feature425', 'feature426', 'feature427', 'feature444', 'feature47', 'feature23', 'feature15', 'feature376', 'feature48', 'feature366', 'feature472', 'feature345', 'feature308', 'feature209', 'feature167', 'feature175', 'feature182', 'feature316', 'feature315', 'feature80', 'feature190', 'feature310', 'feature82', 'feature203', 'feature207', 'feature288', 'feature285', 'feature282', 'feature273', 'feature217', 'feature271', 'feature223', 'feature293', 'feature320', 'feature178', 'feature249', 'feature134', 'feature132', 'feature331', 'feature105', 'feature145', 'feature83', 'feature150', 'feature137', 'feature125', 'feature154', 'feature156', 'feature151', 'feature106', 'feature205', 'feature220', 'feature212', 'feature9', 'feature222', 'feature485', 'feature107', 'feature27', 'feature159', 'feature430', 'feature431', 'feature465', 'feature434', 'feature435', 'feature193', 'feature439', 'feature148', 'feature34', 'feature177', 'feature170', 'feature467', 'feature16', 'feature141', 'feature432', 'feature117', 'feature370', 'feature303', 'feature302', 'feature295', 'feature353', 'feature334', 'feature291', 'feature377', 'feature373', 'feature397', 'feature275', 'feature253', 'feature361', 'feature317', 'feature466', 'feature379', 'feature363', 'feature149', 'feature468', 'feature191', 'feature368', 'feature371', 'feature442', 'feature359', 'feature378', 'feature197', 'feature446', 'feature81', 'feature247', 'feature325', 'feature199', 'feature384', 'feature383', 'feature227', 'feature224', 'feature3', 'feature5', 'feature33', 'feature265', 'feature215', 'feature272', 'feature208', 'feature11', 'feature336', 'feature138', 'feature464', 'feature488', 'feature158', 'feature338', 'feature360', 'feature475', 'feature340', 'feature341', 'feature354', 'feature342', 'feature328', 'feature239', 'feature344', 'feature343', 'feature382', 'feature79', 'feature43', 'feature42', 'feature165', 'feature461', 'feature38', 'feature367', 'feature319', 'feature18', 'feature428', 'feature39', 'feature337', 'feature2', 'feature350', 'feature37', 'feature51', 'feature433', 'feature476', 'feature358', 'feature356', 'feature374', 'feature462', 'feature463', 'feature206', 'feature364', 'feature477', 'feature214', 'feature369', 'feature17', 'feature490', 'feature443', 'feature423', 'feature424', 'feature46', 'feature481']\n",
      "Columns being dropped: []\n",
      "(2831, 498)\n",
      "Per-class MCC:\n",
      "Neutral: 0.8576\n",
      "GOF: 0.5171\n",
      "LOF: 0.7903\n",
      "Overall MCC: 0.8003\n",
      "Model 500 - Test Accuracy: 0.8919109855174849\n",
      "Model 500 - Test Precision: 0.8896711047750963\n",
      "Model 500 - Test Recall: 0.8919109855174849\n",
      "Model 500 - Test F1 Score: 0.8861880769703052\n",
      "Model 500 - Test ROC AUC Score: 0.9419395739747861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.93      0.92      0.92      1339\n",
      "         GOF       0.79      0.36      0.50       152\n",
      "         LOF       0.87      0.92      0.89      1340\n",
      "\n",
      "    accuracy                           0.89      2831\n",
      "   macro avg       0.86      0.74      0.77      2831\n",
      "weighted avg       0.89      0.89      0.89      2831\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.93      0.92      0.92      1339\n",
      "         GOF       0.79      0.36      0.50       152\n",
      "         LOF       0.87      0.92      0.89      1340\n",
      "\n",
      "    accuracy                           0.89      2831\n",
      "   macro avg       0.86      0.74      0.77      2831\n",
      "weighted avg       0.89      0.89      0.89      2831\n",
      "\n",
      "\n",
      "Per-class MCC:\n",
      "Neutral: 0.8576\n",
      "GOF: 0.5171\n",
      "LOF: 0.7903\n",
      "\n",
      "Metrics for model 500 saved to /Users/benzenesea/Desktop/XGBoost-499/more-features/metrics/xgb_df500_metrics.csv\n",
      "Report for model 500 saved to /Users/benzenesea/Desktop/XGBoost-499/more-features/metrics/report/xgb_df500_report.csv\n",
      "Confusion Matrix for model 500 saved to /Users/benzenesea/Desktop/XGBoost-499/more-features/metrics/matrix/xgb_df500_matrix.csv\n",
      "Results for model 500 saved to /Users/benzenesea/Desktop/XGBoost-499/more-features/results/xgb_df500.csv\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Iterate through the entire testing script for each subeset DataFrame in the dictionary. \"\"\"\n",
    "\n",
    "for number in range(500, 501):  \n",
    "    print(f\"Processing model {number}\")\n",
    "    \n",
    "    # Load both datasets.\n",
    "    data = pd.read_csv(f'../data/ranked_subsets/test_features_csv/test_{number}_features.csv', low_memory=False)\n",
    "    print(f'Shape of data: {data.shape}')\n",
    "    X_train = pd.read_csv(f'../data/ranked_subsets/train_features_csv/top_{number}_features.csv', low_memory=False)\n",
    "    print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "    model_name = f'xgb_df{number}'\n",
    "    model_path = f'models/{model_name}'\n",
    "    output_path = f'results/{model_name}.csv'\n",
    "    metrics_path = f'metrics/{model_name}_metrics.csv'\n",
    "    report_path = f'metrics/report/{model_name}_report.csv'\n",
    "    matrix_path = f'metrics/matrix/{model_name}_matrix.csv'\n",
    "\n",
    "    # These lists are used to determine imputation strategies for the specified features (inherited from LoGoFunc)\n",
    "    NEGONE_FEATURES = ['feature487', 'feature489', 'feature491', 'feature492', 'feature493', 'feature494', 'feature495', 'feature496', 'feature497', 'feature498', 'feature499', 'feature458', 'feature4', 'feature6', 'feature10', 'feature13', 'feature31', 'feature35', 'feature36', 'feature46', 'feature47', 'feature48', 'feature49', 'feature45', 'feature50', 'feature51', 'feature52', 'feature53', 'feature54', 'feature55', 'feature56', 'feature57', 'feature58', 'feature59', 'feature60', 'feature61', 'feature62', 'feature63', 'feature64', 'feature65', 'feature66', 'feature67', 'feature68', 'feature69', 'feature70', 'feature71', 'feature72', 'feature73', 'feature74', 'feature75', 'feature76', 'feature77', 'feature84', 'feature85', 'feature86', 'feature87', 'feature88', 'feature89', 'feature90', 'feature91', 'feature92', 'feature93', 'feature94', 'feature95', 'feature96', 'feature97', 'feature98', 'feature99', 'feature100', 'feature101', 'feature102', 'feature103', 'feature105', 'feature107', 'feature108', 'feature109', 'feature110', 'feature111', 'feature112', 'feature113', 'feature114', 'feature115', 'feature116', 'feature117', 'feature118', 'feature119', 'feature120', 'feature121', 'feature122', 'feature123', 'feature124', 'feature125', 'feature126', 'feature127', 'feature128', 'feature129', 'feature130', 'feature131', 'feature132', 'feature133', 'feature134', 'feature135', 'feature136', 'feature137', 'feature138', 'feature139', 'feature140', 'feature141', 'feature142', 'feature143', 'feature144', 'feature145', 'feature146', 'feature147', 'feature148', 'feature149', 'feature150', 'feature151', 'feature152', 'feature153', 'feature154', 'feature155', 'feature156', 'feature157', 'feature158', 'feature159', 'feature160', 'feature161', 'feature162', 'feature163', 'feature164', 'feature165', 'feature166', 'feature167', 'feature168', 'feature169', 'feature170', 'feature171', 'feature172', 'feature173', 'feature174', 'feature175', 'feature176', 'feature177', 'feature178', 'feature179', 'feature180', 'feature181', 'feature182', 'feature183', 'feature184', 'feature185', 'feature186', 'feature187', 'feature188', 'feature189', 'feature190', 'feature191', 'feature192', 'feature193', 'feature194', 'feature195', 'feature196', 'feature197', 'feature198', 'feature199', 'feature200', 'feature201', 'feature202', 'feature203', 'feature204', 'feature205', 'feature206', 'feature207', 'feature208', 'feature209', 'feature210', 'feature211', 'feature212', 'feature213', 'feature214', 'feature215', 'feature216', 'feature217', 'feature218', 'feature219', 'feature220', 'feature221', 'feature222', 'feature223', 'feature224', 'feature225', 'feature226', 'feature227', 'feature228', 'feature229', 'feature230', 'feature231', 'feature232', 'feature233', 'feature234', 'feature235', 'feature236', 'feature237', 'feature238', 'feature239', 'feature240', 'feature241', 'feature242', 'feature243', 'feature244', 'feature245', 'feature246', 'feature247', 'feature248', 'feature249', 'feature250', 'feature251', 'feature252', 'feature253', 'feature254', 'feature255', 'feature256', 'feature257', 'feature258', 'feature259', 'feature260', 'feature261', 'feature262', 'feature263', 'feature264', 'feature265', 'feature266', 'feature267', 'feature268', 'feature269', 'feature270', 'feature271', 'feature272', 'feature273', 'feature274', 'feature275', 'feature276', 'feature277', 'feature278', 'feature279', 'feature280', 'feature281', 'feature282', 'feature283', 'feature284', 'feature285', 'feature286', 'feature287', 'feature288', 'feature289', 'feature290', 'feature291', 'feature292', 'feature293', 'feature294', 'feature295', 'feature296', 'feature297', 'feature298', 'feature299', 'feature300', 'feature301', 'feature302', 'feature303', 'feature304', 'feature305', 'feature306', 'feature307', 'feature308', 'feature309', 'feature310', 'feature311', 'feature312', 'feature313', 'feature314', 'feature315', 'feature316', 'feature317', 'feature318', 'feature319', 'feature320', 'feature321', 'feature322', 'feature323', 'feature324', 'feature325', 'feature326', 'feature327', 'feature328', 'feature329', 'feature330', 'feature331', 'feature332', 'feature333', 'feature334', 'feature335', 'feature336', 'feature337', 'feature338', 'feature339', 'feature340', 'feature341', 'feature342', 'feature343', 'feature344', 'feature345', 'feature346', 'feature347', 'feature348', 'feature349', 'feature355', 'feature356', 'feature357', 'feature358', 'feature359', 'feature360', 'feature361', 'feature362', 'feature363', 'feature364', 'feature365', 'feature366', 'feature367', 'feature368', 'feature369', 'feature373', 'feature374', 'feature375', 'feature376', 'feature421', 'feature422', 'feature423', 'feature424', 'feature425', 'feature426', 'feature427', 'feature428', 'feature429', 'feature430', 'feature431', 'feature432', 'feature433', 'feature434', 'feature435', 'feature436', 'feature437', 'feature438', 'feature439', 'feature440', 'feature441', 'feature442', 'feature443', 'feature444', 'feature445', 'feature446', 'feature447', 'feature448', 'feature459', 'feature460', 'feature461', 'feature462', 'feature463', 'feature464', 'feature465', 'feature466', 'feature467', 'feature471', 'feature472', 'feature473', 'feature474', 'feature475', 'feature476', 'feature477', 'feature478', 'feature479', 'feature480', 'feature481', 'feature482', 'feature483', 'feature484', 'feature485', 'feature486']\n",
    "    MEDIAN_FEATURES = ['feature3', 'feature5', 'feature7', 'feature8', 'feature9', 'feature11', 'feature12', 'feature14', 'feature15', 'feature16', 'feature17', 'feature18', 'feature19', 'feature20', 'feature21', 'feature22', 'feature23', 'feature24', 'feature25', 'feature26', 'feature27', 'feature28', 'feature29', 'feature30', 'feature32', 'feature33', 'feature34', 'feature37', 'feature38', 'feature39', 'feature40', 'feature41', 'feature42', 'feature43', 'feature79', 'feature80', 'feature81', 'feature82', 'feature350', 'feature351', 'feature352', 'feature353', 'feature354', 'feature370', 'feature371', 'feature372', 'feature378', 'feature379', 'feature380', 'feature381', 'feature382', 'feature383', 'feature384', 'feature385', 'feature386', 'feature387', 'feature388', 'feature389', 'feature390', 'feature391', 'feature392', 'feature393', 'feature394', 'feature395', 'feature396', 'feature397', 'feature398', 'feature399', 'feature400', 'feature401', 'feature402', 'feature403', 'feature404', 'feature405', 'feature406', 'feature407', 'feature408', 'feature409', 'feature410', 'feature411', 'feature412', 'feature413', 'feature414', 'feature415', 'feature416', 'feature417', 'feature418', 'feature419', 'feature420', 'feature449', 'feature450', 'feature451', 'feature452', 'feature453', 'feature454', 'feature455', 'feature456', 'feature457', 'feature469', 'feature470']\n",
    "\n",
    "    # Filter NEGONE_FEATURES and MEDIAN_FEATURES based on current X_train columns.\n",
    "    negone_features_filtered = [feature for feature in NEGONE_FEATURES if feature in X_train.columns]\n",
    "    median_features_filtered = [feature for feature in MEDIAN_FEATURES if feature in X_train.columns]\n",
    "\n",
    "    # Redefine NEGONE_FEATURES and MEDIAN_FEATURES with updated values.\n",
    "    NEGONE_FEATURES = negone_features_filtered\n",
    "    MEDIAN_FEATURES = median_features_filtered\n",
    "\n",
    "    print(\"Filtered NEGONE_FEATURES:\", NEGONE_FEATURES)\n",
    "    print(\"Filtered MEDIAN_FEATURES:\", MEDIAN_FEATURES)\n",
    "\n",
    "    def generate_preprocessor(numeric_features, categorical_features, N_JOBS, cat_encode_type, \n",
    "                            do_specificimpute, do_featureselection, \n",
    "                            do_sampling, do_pca, var_thresh, oversample_technique, \n",
    "                            negone_features=NEGONE_FEATURES, median_features=MEDIAN_FEATURES,\n",
    "                            prefix='', do_feature_subset=False, max_features=1, do_removeppi=False, do_removegtex=False):\n",
    "        cat_encoders = [OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, encoded_missing_value=-1), \n",
    "                        OneHotEncoder(sparse=False, handle_unknown='infrequent_if_exist', min_frequency=10)]\n",
    "        categorical_transformer = cat_encoders[cat_encode_type]\n",
    "\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', MinMaxScaler(feature_range =(0, 1), clip=True))])\n",
    "\n",
    "        median_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', MinMaxScaler(feature_range =(0, 1), clip=True))])\n",
    "\n",
    "        negone_transformer = Pipeline(steps=[\n",
    "            ('scaler', MinMaxScaler(feature_range =(0, 1), clip=True)),\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value=-1)),\n",
    "        ])\n",
    "\n",
    "        preprocessor = None\n",
    "        if do_specificimpute:\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('median', median_transformer, median_features),\n",
    "                    ('negone', negone_transformer, negone_features),\n",
    "                    ('cat', categorical_transformer, categorical_features),\n",
    "            ])\n",
    "        else:\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('numeric', numeric_transformer, numeric_features),\n",
    "                    ('cat', categorical_transformer, categorical_features),\n",
    "                ])\n",
    "\n",
    "        vt = VarianceThreshold(threshold=var_thresh)\n",
    "        steps = [('initial', preprocessor), ('removeba', RemoveBeforeAfterTransformer()), ('variance_threshold', vt)]\n",
    "        if do_sampling == 1:\n",
    "            steps.append(('undersampling', RandomUnderSampler(random_state=42)))\n",
    "        if do_sampling == 2:\n",
    "            oversamplers = [SMOTE(n_jobs=N_JOBS,random_state=42), RandomOverSampler(random_state=42)]\n",
    "            steps.append(('oversampling', oversamplers[oversample_technique]))\n",
    "        if do_pca:\n",
    "            steps.append(('pca', PCA()))\n",
    "\n",
    "        preprocessor = Pipeline(steps=steps)\n",
    "        return preprocessor\n",
    "\n",
    "    X_test = data\n",
    "    y_test = pd.read_csv('../data/y_test_id.csv', low_memory=False)\n",
    "    model_type = 'xgb'\n",
    "    num_models = 27\n",
    "\n",
    "    features = X_test.columns.tolist()\n",
    "    print(features)\n",
    "\n",
    "    # Load training data and extract columns (features).\n",
    "    X_train = drop_allnan(X_train)\n",
    "    columns = X_train.columns.tolist()\n",
    "\n",
    "    # Pre-processor generation with multiple parameters that can be tweaked. I used the same values as LoGoFunc\n",
    "    preprocessor = joblib.load(f'{model_path}/preprocessor.joblib')\n",
    "\n",
    "    # Iterate over the models in the ensemble.\n",
    "    models = []\n",
    "    num_models = 27  \n",
    "    for i in range(num_models):\n",
    "        models.append(joblib.load(f'{model_path}/{model_type}_model_{i}.joblib'))\n",
    "\n",
    "    # This encodes the IMPACT feature's column, then drops the ID column.\n",
    "    if 'feature1' in features:\n",
    "        feature1_vals = {'LOW': 0, 'MODIFIER': 1, 'MODERATE': 1.5, 'HIGH': 2}\n",
    "        encoded_feature1s = [feature1_vals[imp] for imp in X_test['feature1']]\n",
    "        X_test = X_test.drop(columns=['feature1'])\n",
    "        X_test['feature1'] = encoded_feature1s\n",
    "    X_test = X_test[columns]\n",
    "    ids = X_test['feature0'].tolist()\n",
    "    X_test = X_test.drop(columns='feature0')\n",
    "\n",
    "    # Make sure the data types are the same, because NumPy arrays are not tolerated in places where DataFrames are expected.\n",
    "    for col in X_test.columns:\n",
    "        X_test[col] = X_test[col].astype(X_train[col].dtype)\n",
    "\n",
    "    # Pre-process the test data.\n",
    "    X_test = transform(X_test, preprocessor)\n",
    "\n",
    "    # Pool the predictions into a list.\n",
    "    all_preds = []\n",
    "    for i in range(num_models):\n",
    "        preds = models[i].predict_proba(X_test)  \n",
    "        all_preds.append(preds)\n",
    "\n",
    "    # Apply the soft-voting function.\n",
    "    y_pred_proba = soft_vote(np.array(all_preds))\n",
    "    y_pred = [np.argmax(p) for p in y_pred_proba]\n",
    "\n",
    "    # Map the labels to numbers.\n",
    "    label_mapping = {'Neutral': 0, 'GOF': 1, 'LOF': 2}\n",
    "    y_test_numeric = [label_mapping[label] for label in y_test['label']]\n",
    "\n",
    "    # Compute class-wise MCC.\n",
    "    mcc_per_class = {}\n",
    "    for i, class_name in enumerate(['Neutral', 'GOF', 'LOF']):\n",
    "        y_true_binary = (np.array(y_test_numeric) == i).astype(int)\n",
    "        y_pred_binary = (np.array(y_pred) == i).astype(int)\n",
    "        mcc_per_class[class_name] = matthews_corrcoef(y_true_binary, y_pred_binary)\n",
    "\n",
    "    overall_mcc = matthews_corrcoef(y_test_numeric, y_pred)\n",
    "\n",
    "    print(\"Per-class MCC:\")\n",
    "    for class_name, mcc_value in mcc_per_class.items():\n",
    "        print(f\"{class_name}: {mcc_value:.4f}\")\n",
    "    print(f\"Overall MCC: {overall_mcc:.4f}\")\n",
    "    \n",
    "    def format_confusion_matrix(conf_matrix):\n",
    "        return \"\\n\".join([\",\".join(map(str, row)) for row in conf_matrix])\n",
    "\n",
    "    # Perform the evaluation using SciKit-learn's metrics.\n",
    "    accuracy = accuracy_score(y_test_numeric, y_pred)\n",
    "    precision = precision_score(y_test_numeric, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test_numeric, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test_numeric, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_test_numeric, y_pred_proba, multi_class='ovo')\n",
    "    conf_matrix = confusion_matrix(y_test_numeric, y_pred)\n",
    "\n",
    "    # Print the recorded metrics.\n",
    "    print(f'Model {number} - Test Accuracy: {accuracy}')\n",
    "    print(f'Model {number} - Test Precision: {precision}')\n",
    "    print(f'Model {number} - Test Recall: {recall}')\n",
    "    print(f'Model {number} - Test F1 Score: {f1}')\n",
    "    print(f'Model {number} - Test ROC AUC Score: {roc_auc}')\n",
    "\n",
    "    # Compute the remaining class-wise metrics.\n",
    "    report = classification_report(y_test_numeric, y_pred, target_names=['Neutral', 'GOF', 'LOF'])\n",
    "    print(report)\n",
    "    custom_report = classification_report(y_test_numeric, y_pred, target_names=['Neutral', 'GOF', 'LOF'])\n",
    "    custom_report += \"\\n\\nPer-class MCC:\\n\"\n",
    "    for class_name, mcc_value in mcc_per_class.items():\n",
    "        custom_report += f\"{class_name}: {mcc_value:.4f}\\n\"\n",
    "    print(custom_report)\n",
    "\n",
    "    # Export the metrics to a CSV.\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Model': [number],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1 Score': [f1],\n",
    "        'ROC AUC Score': [roc_auc],\n",
    "        'Overall MCC': [overall_mcc]\n",
    "    })\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "    print(f\"Metrics for model {number} saved to {metrics_path}\")\n",
    "\n",
    "    # Export classification report to CSV.\n",
    "    report_df = pd.DataFrame({\n",
    "        'Classification Report': [custom_report]\n",
    "    })\n",
    "    report_df.to_csv(report_path, index=False, quoting=0)\n",
    "    print(f\"Report for model {number} saved to {report_path}\")\n",
    "\n",
    "    # Generate the confusion matrix.\n",
    "    matrix_df = pd.DataFrame(conf_matrix, \n",
    "                            columns=['Predicted Neutral', 'Predicted GOF', 'Predicted LOF'],\n",
    "                            index=['Actual Neutral', 'Actual GOF', 'Actual LOF'])\n",
    "\n",
    "    # Export matrix to CSV.\n",
    "    matrix_df.to_csv(matrix_path, quoting=0)\n",
    "    print(f\"Confusion Matrix for model {number} saved to {matrix_path}\")\n",
    "\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(y_pred)):\n",
    "        out.append([ids[i], ['Neutral', 'GOF', 'LOF'][y_pred[i]], *y_pred_proba[i]])\n",
    "    out = pd.DataFrame(out, columns=['feature0', 'prediction', 'LoGoFunc_Neutral', 'LoGoFunc_GOF', 'LoGoFunc_LOF'])\n",
    "    out.to_csv(output_path, index=None)\n",
    "\n",
    "    print(f\"Results for model {number} saved to {output_path}\")\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to metrics/combined_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This combines all of the individual metrics into one file. \"\"\"\n",
    "\n",
    "metrics_dir = 'metrics'\n",
    "\n",
    "# Init list to hold the df's.\n",
    "dfs = []\n",
    "\n",
    "# Iterate over every metric file.\n",
    "for i in range(1, 500): \n",
    "    file_path = os.path.join(metrics_dir, f'xgb_df{i}_metrics.csv')\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Combine the df's.\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Sort by the 'Model' column.s\n",
    "combined_df = combined_df.sort_values('Model')\n",
    "combined_df.set_index('Model', inplace=True)\n",
    "\n",
    "# Save new CSV file.\n",
    "output_path = 'metrics/combined_metrics.csv'\n",
    "combined_df.to_csv(output_path)\n",
    "\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to metrics/ranked_by_accuracy.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This ranks the models according to accuracy. \"\"\"\n",
    "\n",
    "input_path = 'metrics/combined_metrics.csv'\n",
    "combined_df = pd.read_csv(input_path, index_col='Model')\n",
    "\n",
    "# Sort ACC from low to high.\n",
    "sorted_df = combined_df.sort_values('Accuracy', ascending=True)\n",
    "\n",
    "# New df only needs 'Model' and 'Accuracy' columns.\n",
    "rankings_df = pd.DataFrame({\n",
    "    'Model': sorted_df.index,\n",
    "    'Accuracy': sorted_df['Accuracy']\n",
    "})\n",
    "\n",
    "# Reset index so 'Model' is normal column.\n",
    "rankings_df = rankings_df.reset_index(drop=True)\n",
    "\n",
    "# Save new CSV file.\n",
    "output_path = 'metrics/ranked_by_accuracy.csv'\n",
    "rankings_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to metrics/ranked_by_precision.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This ranks the models according to precision. \"\"\"\n",
    "\n",
    "input_path = 'metrics/combined_metrics.csv'\n",
    "combined_df = pd.read_csv(input_path, index_col='Model')\n",
    "\n",
    "# Sort PREC from low to high.\n",
    "sorted_df = combined_df.sort_values('Precision', ascending=True)\n",
    "\n",
    "# New df only needs 'Model' and 'Precision' columns.\n",
    "rankings_df = pd.DataFrame({\n",
    "    'Model': sorted_df.index,\n",
    "    'Precision': sorted_df['Precision']\n",
    "})\n",
    "\n",
    "# Reset index so 'Model' is normal column.\n",
    "rankings_df = rankings_df.reset_index(drop=True)\n",
    "\n",
    "# Save new CSV file.\n",
    "output_path = 'metrics/ranked_by_precision.csv'\n",
    "rankings_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to metrics/ranked_by_recall.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This ranks the models according to recall. \"\"\"\n",
    "\n",
    "input_path = 'metrics/combined_metrics.csv'\n",
    "combined_df = pd.read_csv(input_path, index_col='Model')\n",
    "\n",
    "# Sort REC from low to high.\n",
    "sorted_df = combined_df.sort_values('Recall', ascending=True)\n",
    "\n",
    "# New df only needs 'Model' and 'Recall' columns.\n",
    "rankings_df = pd.DataFrame({\n",
    "    'Model': sorted_df.index,\n",
    "    'Recall': sorted_df['Recall']\n",
    "})\n",
    "\n",
    "# Reset index so 'Model' is normal column.\n",
    "rankings_df = rankings_df.reset_index(drop=True)\n",
    "\n",
    "# Save new CSV file.\n",
    "output_path = 'metrics/ranked_by_recall.csv'\n",
    "rankings_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to metrics/ranked_by_f1.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This ranks the models according to F1-score. \"\"\"\n",
    "\n",
    "input_path = 'metrics/combined_metrics.csv'\n",
    "combined_df = pd.read_csv(input_path, index_col='Model')\n",
    "\n",
    "# Sort F1 from low to high.\n",
    "sorted_df = combined_df.sort_values('F1 Score', ascending=True)\n",
    "\n",
    "# New df only needs 'Model' and 'F1 Score' columns.\n",
    "rankings_df = pd.DataFrame({\n",
    "    'Model': sorted_df.index,\n",
    "    'F1_Score': sorted_df['F1 Score']\n",
    "})\n",
    "\n",
    "# Reset index so 'Model' is normal column.\n",
    "rankings_df = rankings_df.reset_index(drop=True)\n",
    "\n",
    "# Save new CSV file.\n",
    "output_path = 'metrics/ranked_by_f1.csv'\n",
    "rankings_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to metrics/ranked_by_roc_auc.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This ranks the models according to ROC AUC. \"\"\"\n",
    "\n",
    "\n",
    "input_path = 'metrics/combined_metrics.csv'\n",
    "combined_df = pd.read_csv(input_path, index_col='Model')\n",
    "\n",
    "# ROC AUC Score from low to high.\n",
    "sorted_df = combined_df.sort_values('ROC AUC Score', ascending=True)\n",
    "\n",
    "# New df only needs 'Model' and 'ROC AUC' columns.\n",
    "rankings_df = pd.DataFrame({\n",
    "    'Model': sorted_df.index,\n",
    "    'ROC_AUC_Score': sorted_df['ROC AUC Score']\n",
    "})\n",
    "\n",
    "# Reset index so 'Model' is normal column.\n",
    "rankings_df = rankings_df.reset_index(drop=True)\n",
    "\n",
    "# Save new CSV.\n",
    "output_path = 'metrics/ranked_by_roc_auc.csv'\n",
    "rankings_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logofunc3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
