{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Classifier Cross-Validation, Training, Testing, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib, utils, json, csv, ast\n",
    "import itertools\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.special import softmax\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score, ParameterSampler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lists are used to determine imputation strategies for the specified features (inherited from LoGoFunc)\n",
    "NEGONE_FEATURES = ['MOD_RES','REGION','INTERACTION_REGION','REQUIRED_FOR_INTER','ATP_binding_gbind','Ca2+_binding_gbind','DNA_binding_gbind','HEME_binding_gbind','Mg2+_binding_gbind','Mn2+_binding_gbind','RNA_binding_gbind','Dist2Mutation','BLOSUM62','ProteinLengthChange','TSSDistance','1000Gp3_AF','UK10K_AF','gnomAD_exomes_AF','gnomAD_genomes_AF','MSC_95CI','rel_cDNA_pos','rel_CDS_pos','rel_prot_pos','GDI','Selective_pressure','Clarks_distance','CDS_len','Number_of_paralogs','denovo_Zscore','RVIS','Indispensability_score','RSA','ASA','RSA_Zfit','before_RSA_3','before_RSA_8','before_RSA_15','after_RSA_3','after_RSA_8','after_RSA_15','before_ASA_3','before_ASA_8','before_ASA_15','after_ASA_3','after_ASA_8','after_ASA_15','Phosphorylation','Acetylation','Methylation','Ubiquitination','Glycosylation','PTM','AF_Relative_ASA','IUPRED2','ANCHOR2','before_IUPRED_3','before_IUPRED_8','before_IUPRED_15','after_IUPRED_3','after_IUPRED_8','after_IUPRED_15','before_ANCHOR_3','before_ANCHOR_8','before_ANCHOR_15','after_ANCHOR_3','after_ANCHOR_8','after_ANCHOR_15','A3D_SCORE','n_contacts','distance_com','concavity_score','S_DDG[SEQ]','S_DDG[3D]','hgmd_mutcount','gnomsingle_mutcount','gnom_mutcount','AF_confidence','isHomomultimer','num_interactions','ppi_combined_0','ppi_combined_1','ppi_combined_2','ppi_combined_3','ppi_combined_4','ppi_combined_5','ppi_combined_6','ppi_combined_7','ppi_combined_8','ppi_combined_9','ppi_combined_10','ppi_combined_11','ppi_combined_12','ppi_combined_13','ppi_combined_14','ppi_combined_15','ppi_combined_16','ppi_combined_17','ppi_combined_18','ppi_combined_19','ppi_combined_20','ppi_combined_21','ppi_combined_22','ppi_combined_23','ppi_combined_24','ppi_combined_25','ppi_combined_26','ppi_combined_27','ppi_combined_28','ppi_combined_29','ppi_combined_30','ppi_combined_31','ppi_combined_32','ppi_combined_33','ppi_combined_34','ppi_combined_35','ppi_combined_36','ppi_combined_37','ppi_combined_38','ppi_combined_39','ppi_combined_40','ppi_combined_41','ppi_combined_42','ppi_combined_43','ppi_combined_44','ppi_combined_45','ppi_combined_46','ppi_combined_47','ppi_combined_48','ppi_combined_49','ppi_combined_50','ppi_combined_51','ppi_combined_52','ppi_combined_53','ppi_combined_54','ppi_combined_55','ppi_combined_56','ppi_combined_57','ppi_combined_58','ppi_combined_59','ppi_combined_60','ppi_combined_61','ppi_combined_62','ppi_combined_63','s_het','DRNApredDNAscore_aa_window_3_prev','DRNApredDNAscore_aa_window_8_prev','DRNApredDNAscore_aa_window_15_prev','DRNApredDNAscore_aa_window_3_next','DRNApredDNAscore_aa_window_8_next','DRNApredDNAscore_aa_window_15_next','DRNApredDNAscore_aa','ASAquick_normscore_aa_window_3_prev','ASAquick_normscore_aa_window_8_prev','ASAquick_normscore_aa_window_15_prev','ASAquick_normscore_aa_window_3_next','ASAquick_normscore_aa_window_8_next','ASAquick_normscore_aa_window_15_next','ASAquick_normscore_aa','ASAquick_rawscore_aa_window_3_prev','ASAquick_rawscore_aa_window_8_prev','ASAquick_rawscore_aa_window_15_prev','ASAquick_rawscore_aa_window_3_next','ASAquick_rawscore_aa_window_8_next','ASAquick_rawscore_aa_window_15_next','ASAquick_rawscore_aa','DFLpredScore_aa_window_3_prev','DFLpredScore_aa_window_8_prev','DFLpredScore_aa_window_15_prev','DFLpredScore_aa_window_3_next','DFLpredScore_aa_window_8_next','DFLpredScore_aa_window_15_next','DFLpredScore_aa','DRNApredRNAscore_aa_window_3_prev','DRNApredRNAscore_aa_window_8_prev','DRNApredRNAscore_aa_window_15_prev','DRNApredRNAscore_aa_window_3_next','DRNApredRNAscore_aa_window_8_next','DRNApredRNAscore_aa_window_15_next','DRNApredRNAscore_aa','DisoDNAscore_aa_window_3_prev','DisoDNAscore_aa_window_8_prev','DisoDNAscore_aa_window_15_prev','DisoDNAscore_aa_window_3_next','DisoDNAscore_aa_window_8_next','DisoDNAscore_aa_window_15_next','DisoDNAscore_aa','DisoPROscore_aa_window_3_prev','DisoPROscore_aa_window_8_prev','DisoPROscore_aa_window_15_prev','DisoPROscore_aa_window_3_next','DisoPROscore_aa_window_8_next','DisoPROscore_aa_window_15_next','DisoPROscore_aa','DisoRNAscore_aa_window_3_prev','DisoRNAscore_aa_window_8_prev','DisoRNAscore_aa_window_15_prev','DisoRNAscore_aa_window_3_next','DisoRNAscore_aa_window_8_next','DisoRNAscore_aa_window_15_next','DisoRNAscore_aa','MMseq2_conservation_level_aa_window_3_prev','MMseq2_conservation_level_aa_window_8_prev','MMseq2_conservation_level_aa_window_15_prev','MMseq2_conservation_level_aa_window_3_next','MMseq2_conservation_level_aa_window_8_next','MMseq2_conservation_level_aa_window_15_next','MMseq2_conservation_level_aa','MMseq2_conservation_score_aa_window_3_prev','MMseq2_conservation_score_aa_window_8_prev','MMseq2_conservation_score_aa_window_15_prev','MMseq2_conservation_score_aa_window_3_next','MMseq2_conservation_score_aa_window_8_next','MMseq2_conservation_score_aa_window_15_next','MMseq2_conservation_score_aa','MoRFchibiScore_aa_window_3_prev','MoRFchibiScore_aa_window_8_prev','MoRFchibiScore_aa_window_15_prev','MoRFchibiScore_aa_window_3_next','MoRFchibiScore_aa_window_8_next','MoRFchibiScore_aa_window_15_next','MoRFchibiScore_aa','PSIPRED_helix_aa_window_3_prev','PSIPRED_helix_aa_window_8_prev','PSIPRED_helix_aa_window_15_prev','PSIPRED_helix_aa_window_3_next','PSIPRED_helix_aa_window_8_next','PSIPRED_helix_aa_window_15_next','PSIPRED_helix_aa','PSIPRED_strand_aa_window_3_prev','PSIPRED_strand_aa_window_8_prev','PSIPRED_strand_aa_window_15_prev','PSIPRED_strand_aa_window_3_next','PSIPRED_strand_aa_window_8_next','PSIPRED_strand_aa_window_15_next','PSIPRED_strand_aa','SCRIBERscore_aa_window_3_prev','SCRIBERscore_aa_window_8_prev','SCRIBERscore_aa_window_15_prev','SCRIBERscore_aa_window_3_next','SCRIBERscore_aa_window_8_next','SCRIBERscore_aa_window_15_next','SCRIBERscore_aa','SignalP_score_aa_window_3_prev','SignalP_score_aa_window_8_prev','SignalP_score_aa_window_15_prev','SignalP_score_aa_window_3_next','SignalP_score_aa_window_8_next','SignalP_score_aa_window_15_next','SignalP_score_aa','gtex_Adipose_-_Subcutaneous','gtex_Adipose_-_Visceral_(Omentum)','gtex_Adrenal_Gland','gtex_Artery_-_Aorta','gtex_Artery_-_Coronary','gtex_Artery_-_Tibial','gtex_Bladder','gtex_Brain_-_Amygdala','gtex_Brain_-_Anterior_cingulate_cortex_(BA24)','gtex_Brain_-_Caudate_(basal_ganglia)','gtex_Brain_-_Cerebellar_Hemisphere','gtex_Brain_-_Cerebellum','gtex_Brain_-_Cortex','gtex_Brain_-_Frontal_Cortex_(BA9)','gtex_Brain_-_Hippocampus','gtex_Brain_-_Hypothalamus','gtex_Brain_-_Nucleus_accumbens_(basal_ganglia)','gtex_Brain_-_Putamen_(basal_ganglia)','gtex_Brain_-_Spinal_cord_(cervical_c-1)','gtex_Brain_-_Substantia_nigra','gtex_Breast_-_Mammary_Tissue','gtex_Cells_-_Cultured_fibroblasts','gtex_Cells_-_EBV-transformed_lymphocytes','gtex_Cervix_-_Ectocervix','gtex_Cervix_-_Endocervix','gtex_Colon_-_Sigmoid','gtex_Colon_-_Transverse','gtex_Esophagus_-_Gastroesophageal_Junction','gtex_Esophagus_-_Mucosa','gtex_Esophagus_-_Muscularis','gtex_Fallopian_Tube','gtex_Heart_-_Atrial_Appendage','gtex_Heart_-_Left_Ventricle','gtex_Kidney_-_Cortex','gtex_Kidney_-_Medulla','gtex_Liver','gtex_Lung','gtex_Minor_Salivary_Gland','gtex_Muscle_-_Skeletal','gtex_Nerve_-_Tibial','gtex_Ovary','gtex_Pancreas','gtex_Pituitary','gtex_Prostate','gtex_Skin_-_Not_Sun_Exposed_(Suprapubic)','gtex_Skin_-_Sun_Exposed_(Lower_leg)','gtex_Small_Intestine_-_Terminal_Ileum','gtex_Spleen','gtex_Stomach','gtex_Testis','gtex_Thyroid','gtex_Uterus','gtex_Vagina','gtex_Whole_Blood','haplo','haplo_imputed','PHOSPHORYLATION','ACETYLATION','UBIQUITINATION','S-NITROSYLATION','N-GLYCOSYLATION','METHYLATION','O-GLYCOSYLATION','MYRISTOYLATION','C-GLYCOSYLATION','SUMOYLATION','S-GLYCOSYLATION','polyphen_nobs','polyphen_normasa','polyphen_dvol','polyphen_dprop','polyphen_bfact','polyphen_hbonds','polyphen_avenhet','polyphen_mindhet','polyphen_avenint','polyphen_mindint','polyphen_avensit','polyphen_mindsit','polyphen_idpmax','polyphen_idpsnp','polyphen_idqmin','motifECount','motifEHIPos','motifEScoreChng','Dst2Splice','motifDist','EncodeH3K4me1-sum','EncodeH3K4me1-max','EncodeH3K4me2-sum','EncodeH3K4me2-max','EncodeH3K4me3-sum','EncodeH3K4me3-max','EncodeH3K9ac-sum','EncodeH3K9ac-max','EncodeH3K9me3-sum','EncodeH3K9me3-max','EncodeH3K27ac-sum','EncodeH3K27ac-max','EncodeH3K27me3-sum','EncodeH3K27me3-max','EncodeH3K36me3-sum','EncodeH3K36me3-max','EncodeH3K79me2-sum','EncodeH3K79me2-max','EncodeH4K20me1-sum','EncodeH4K20me1-max','EncodeH2AFZ-sum','EncodeH2AFZ-max','EncodeDNase-sum','EncodeDNase-max','EncodetotalRNA-sum','EncodetotalRNA-max','Grantham_x','Freq100bp','Rare100bp','Sngl100bp','Freq1000bp','Rare1000bp','Sngl1000bp','Freq10000bp','Rare10000bp','Sngl10000bp','RemapOverlapTF','RemapOverlapCL','Charge','Volume','Hydrophobicity','Polarity','Ex','PAM250','JM','HGMD2003','VB','Transition','COSMIC','COSMICvsSWISSPROT','HAPMAP','COSMICvsHAPMAP',]\n",
    "MEDIAN_FEATURES = ['CADD_raw','Conservation','MaxEntScan_alt','MaxEntScan_diff','MaxEntScan_ref','ada_score','rf_score','FATHMM_score','GERPplus_plus_NR','GERPplus_plus_RS','GM12878_fitCons_score','GenoCanyon_score','H1_hESC_fitCons_score','HUVEC_fitCons_score','LINSIGHT','LIST_S2_score','LRT_score','M_CAP_score','MPC_score','MVP_score','MutationAssessor_score','MutationTaster_score','PROVEAN_score','SiPhy_29way_logOdds','VEST4_score','fathmm_MKL_coding_score','fathmm_XF_coding_score','integrated_fitCons_score','phastCons100way_vertebrate','phastCons17way_primate','phastCons30way_mammalian','phyloP100way_vertebrate','phyloP17way_primate','phyloP30way_mammalian','Condel_score','SIFT_score','NearestExonJB_distance','NearestExonJB_len','Dominant_probability','Recessive_probability','polyphen_dscore','polyphen_score1','polyphen_score2','ConsScore','GC','CpG','minDistTSS','minDistTSE','priPhCons','mamPhCons','verPhCons','priPhyloP','mamPhyloP','verPhyloP','bStatistic_y','targetScan','mirSVR-Score','mirSVR-E','mirSVR-Aln','cHmm_E1','cHmm_E2','cHmm_E3','cHmm_E4','cHmm_E5','cHmm_E6','cHmm_E7','cHmm_E8','cHmm_E9','cHmm_E10','cHmm_E11','cHmm_E12','cHmm_E13','cHmm_E14','cHmm_E15','cHmm_E16','cHmm_E17','cHmm_E18','cHmm_E19','cHmm_E20','cHmm_E21','cHmm_E22','cHmm_E23','cHmm_E24','cHmm_E25','GerpRS','GerpRSpval','GerpN','GerpS','tOverlapMotifs','SpliceAI-acc-gain','SpliceAI-acc-loss','SpliceAI-don-gain','SpliceAI-don-loss','MMSp_acceptorIntron','MMSp_acceptor','MMSp_exon','MMSp_donor','MMSp_donorIntron','dbscSNV-ada_score','dbscSNV-rf_score',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the correct training data (missing `Protein_dom`).\n",
    "X_train = pd.read_csv('../data/X_train_500.csv', low_memory=False)\n",
    "y_train = pd.read_csv('../data/y_train_id.csv', low_memory=False)\n",
    "model_type = 'mlp' \n",
    "model_path = f'../models/{model_type}-validation'\n",
    "output_path = f'../results/{model_type}-validation.csv'\n",
    "metrics_file = f'../metrics/{model_type}-validation-metrics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial took 0.48466992378234863 to run.\n",
      "(25546, 498)\n",
      "(25546, 472)\n",
      "removeba took 0.015001058578491211 to run.\n",
      "variance_threshold took 0.0746619701385498 to run.\n",
      "oversampling took 0.09935998916625977 to run.\n"
     ]
    }
   ],
   "source": [
    "# This is used to drop columns that only contain NaN values.\n",
    "def drop_allnan(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].isna().sum() == len(data):\n",
    "            data = data.drop(columns=col)\n",
    "    return data\n",
    "\n",
    "# This encodes the IMPACT feature's column.\n",
    "X_train = drop_allnan(X_train)\n",
    "impact_vals = {'LOW': 0, 'MODIFIER': 1, 'MODERATE': 1.5, 'HIGH': 2}\n",
    "encoded_impacts = [impact_vals[imp] for imp in X_train['IMPACT']]\n",
    "X_train = X_train.drop(columns=['IMPACT'])\n",
    "X_train['IMPACT'] = encoded_impacts\n",
    "\n",
    "# Conditional imputation based on feature type.\n",
    "numeric_features = X_train.select_dtypes(include=['number']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Pre-processor generation with multiple parameters that can be tweaked. I used the same values as LoGoFunc.\n",
    "preprocessor = utils.generate_preprocessor(numeric_features, categorical_features, 40, 0,\n",
    "                            1, 0, 2, 0, 0, 1,\n",
    "                            prefix='light0', do_feature_subset=True, max_features=1)\n",
    "\n",
    "# Encoding the labels.\n",
    "y_train_enc = []\n",
    "for lab in y_train['label']:\n",
    "    if lab == 'GOF':\n",
    "        y_train_enc.append(1)\n",
    "    elif lab == 'LOF':\n",
    "        y_train_enc.append(2)\n",
    "    else:\n",
    "        y_train_enc.append(0)\n",
    "y_train = y_train_enc\n",
    "\n",
    "X_train, y_train = utils.preprocess(preprocessor, X_train, y_train)\n",
    "\n",
    "# This creates a directory for the preprocessor and trained models.\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "joblib.dump(preprocessor, f'{model_path}/preprocessor.joblib')\n",
    "\n",
    "# This is where the train-val split happens in a 80-20 ratio.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch wants them as numpy arrays.\n",
    "X_train = X_train.values if hasattr(X_train, 'values') else np.array(X_train)\n",
    "y_train = y_train.values if hasattr(y_train, 'values') else np.array(y_train)\n",
    "X_val = X_val.values if hasattr(X_val, 'values') else np.array(X_val)\n",
    "y_val = y_val.values if hasattr(y_val, 'values') else np.array(y_val)\n",
    "\n",
    "# Convert data to PyTorch tensors.\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.9178551456525945\n",
      "Fitting 3 folds for each of 121 candidates, totalling 363 fits\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=22.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=22.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=22.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=25.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=25.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=26.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=31.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=31.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=31.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=11.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=12.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=12.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=17.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=17.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=18.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=64.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=64.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=64.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=37.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=31.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=37.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=31.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=37.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=31.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 7.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 7.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 7.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=45.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=45.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=46.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=12.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=26.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=12.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=26.2min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=12.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=26.1min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=39.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=39.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=39.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=16.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=16.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=16.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=69.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=69.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=69.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=47.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=47.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=47.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=39.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=39.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=40.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=44.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=44.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=44.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=22.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=22.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=22.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=22.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=22.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=23.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=16.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=16.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=16.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=11.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=11.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=11.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=49.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=49.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=49.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=13.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=18.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=13.2min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=18.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=18.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=13.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=16.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=16.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=16.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=70.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=70.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=71.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 8.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 8.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 8.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=48.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=48.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=48.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=13.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=13.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=13.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=51.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=51.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=51.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=72.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=72.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=73.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=23.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=23.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=23.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=32.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=32.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=32.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=69.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=69.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=70.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=51.1min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=13.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=13.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=51.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=51.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=13.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=17.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=17.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=17.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=73.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=73.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=74.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 7.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 7.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 8.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=36.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=36.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=36.2min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=40.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=40.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=40.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=35.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=35.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=35.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=14.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=14.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=14.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 7.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 7.1min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 7.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=26.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=26.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=26.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=51.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=51.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=51.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=17.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=17.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=17.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=44.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=44.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=44.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=52.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=51.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=52.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=25.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=25.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=25.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 8.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 8.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 8.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=42.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=42.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 8.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 8.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 8.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=42.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=14.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=15.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=25.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=25.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=15.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=25.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=15.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=14.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=15.2min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=15.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=52.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=29.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=14.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=15.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=29.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=53.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=52.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=29.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 6.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 6.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time= 6.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=16.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=16.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=16.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=23.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=23.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=32.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=23.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=32.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=32.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=51.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=51.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=51.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=34.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=34.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=34.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 6.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 6.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time= 6.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=19.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=19.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=19.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=27.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=27.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=28.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=49.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=49.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=49.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=56.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=56.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=56.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=16.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=16.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=16.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=19.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=19.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=19.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=28.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=28.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=19.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=28.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=18.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=19.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=14.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=14.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=14.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=26.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=25.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=25.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=40.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=39.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=39.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=14.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=72.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=14.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=14.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=73.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=29.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=29.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=73.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=29.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=11.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=12.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=12.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=25.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=25.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=25.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=24.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=24.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=24.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=10.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=11.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=10.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=31.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=31.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=45.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=44.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=44.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=31.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=21.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=21.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.001; total time=21.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=22.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=22.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=23.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=24.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=24.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=24.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=12.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=12.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=12.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=32.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=32.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=32.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=45.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=46.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=46.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 7.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 7.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=51.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 8.0min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=51.6min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=51.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=15.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 5.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=15.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 5.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=15.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 5.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=12.2min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=12.2min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=12.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=21.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=21.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=21.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=32.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=14.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=32.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=14.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=32.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time=15.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=65.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=65.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=16.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=16.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=16.2min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=66.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=41.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=41.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=41.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=69.0min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=68.6min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=68.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=49.7min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=49.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=0.001; total time=50.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=69.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=69.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=70.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=26.5min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=26.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=23.1min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=26.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=23.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=23.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=22.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=23.1min\n",
      "[CV] END batch_size=32, dropout_rate=0.3, epochs=500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=23.3min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=39.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=39.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=39.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=24.7min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=32.8min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=32.5min\n",
      "[CV] END batch_size=32, dropout_rate=0.5, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=32.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=24.9min\n",
      "[CV] END batch_size=128, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=1e-05; total time=24.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=47.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=48.1min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=48.6min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=26.2min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=26.2min\n",
      "[CV] END batch_size=128, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=26.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=32.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=32.3min\n",
      "[CV] END batch_size=64, dropout_rate=0.5, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=1e-05; total time=32.4min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 7.8min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 7.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=500, hidden_sizes=[256, 128, 64], learning_rate=0.0001; total time= 7.9min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=68.3min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=68.4min\n",
      "[CV] END batch_size=32, dropout_rate=0.4, epochs=1500, hidden_sizes=[512, 256, 128, 64], learning_rate=0.0001; total time=69.2min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=28.5min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=28.4min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=14.0min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=14.1min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1500, hidden_sizes=[256, 128, 64], learning_rate=1e-05; total time=13.9min\n",
      "[CV] END batch_size=64, dropout_rate=0.3, epochs=1000, hidden_sizes=[512, 256, 128, 64], learning_rate=0.001; total time=27.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=18.8min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=18.7min\n",
      "[CV] END batch_size=128, dropout_rate=0.4, epochs=1000, hidden_sizes=[512, 256, 128], learning_rate=0.0001; total time=18.6min\n",
      "Best parameters found: {'learning_rate': 1e-05, 'hidden_sizes': [512, 256, 128], 'epochs': 1500, 'dropout_rate': 0.5, 'batch_size': 64}\n",
      "Top 27 parameter sets:\n",
      "Set 1:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 32\n",
      "\n",
      "Set 2:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.3\n",
      "  batch_size: 64\n",
      "\n",
      "Set 3:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 32\n",
      "\n",
      "Set 4:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 128\n",
      "\n",
      "Set 5:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 128\n",
      "\n",
      "Set 6:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "\n",
      "Set 7:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 64\n",
      "\n",
      "Set 8:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 32\n",
      "\n",
      "Set 9:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 128\n",
      "\n",
      "Set 10:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 64\n",
      "\n",
      "Set 11:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 64\n",
      "\n",
      "Set 12:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 128\n",
      "\n",
      "Set 13:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 128\n",
      "\n",
      "Set 14:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.4\n",
      "  batch_size: 32\n",
      "\n",
      "Set 15:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 128\n",
      "\n",
      "Set 16:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 128\n",
      "\n",
      "Set 17:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 32\n",
      "\n",
      "Set 18:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 32\n",
      "\n",
      "Set 19:\n",
      "  learning_rate: 0.0001\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 128\n",
      "\n",
      "Set 20:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 128\n",
      "\n",
      "Set 21:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 64\n",
      "\n",
      "Set 22:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 32\n",
      "\n",
      "Set 23:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128, 64]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 64\n",
      "\n",
      "Set 24:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1000\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 64\n",
      "\n",
      "Set 25:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 64\n",
      "\n",
      "Set 26:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [256, 128, 64]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 32\n",
      "\n",
      "Set 27:\n",
      "  learning_rate: 1e-05\n",
      "  hidden_sizes: [512, 256, 128]\n",
      "  epochs: 1500\n",
      "  dropout_rate: 0.5\n",
      "  batch_size: 64\n",
      "\n",
      "Validation Accuracy: 0.925181233757352\n",
      "Validation Precision: 0.9251997768647021\n",
      "Validation Recall: 0.925181233757352\n",
      "Validation F1 Score: 0.9247748697574999\n",
      "Validation ROC AUC Score: 0.9838332787456232\n",
      "Confusion Matrix:\n",
      "[[2113   20  299]\n",
      " [   0 2437    3]\n",
      " [ 174   51 2214]]\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.hidden = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.hidden(x)\n",
    "\n",
    "# Define the search space.\n",
    "param_dist = {\n",
    "    'hidden_sizes': [[512, 256, 128, 64], [256, 128, 64], [512, 256, 128]],\n",
    "    'dropout_rate': [0.3, 0.4, 0.5],\n",
    "    'learning_rate': [0.001, 0.0001, 0.00001],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [500, 1000, 1500]\n",
    "}\n",
    "\n",
    "def train_model(model, X_train, y_train, epochs, lr, batch_size):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = accuracy_score(y.numpy(), predicted.numpy())\n",
    "    return accuracy\n",
    "\n",
    "class MLPWrapper:\n",
    "    def __init__(self, input_size, output_size, hidden_sizes=None, dropout_rate=None, learning_rate=None, batch_size=None, epochs=None):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.from_numpy(X).float()\n",
    "        else:\n",
    "            X = X.clone().detach().float()\n",
    "        \n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.from_numpy(y).long()\n",
    "        else:\n",
    "            y = y.clone().detach().long()\n",
    "        \n",
    "        self.model = MLP(self.input_size, self.hidden_sizes, self.output_size, self.dropout_rate)\n",
    "        self.model = train_model(self.model, X, y, self.epochs, self.learning_rate, self.batch_size)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.from_numpy(X).float()\n",
    "        else:\n",
    "            X = X.clone().detach().float()\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        return predicted.numpy()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.from_numpy(X).float()\n",
    "        else:\n",
    "            X = X.clone().detach().float()\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X)\n",
    "            probabilities = nn.functional.softmax(outputs, dim=1)\n",
    "        return probabilities.numpy()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"input_size\": self.input_size,\n",
    "            \"output_size\": self.output_size,\n",
    "            \"hidden_sizes\": self.hidden_sizes,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "     \n",
    "\n",
    "# init wrapper.\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(torch.unique(y_train))\n",
    "mlp_wrapper = MLPWrapper(input_size, output_size, [512, 256, 128, 64], 0.4, 0.0001, 64, 1000)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_val_score(mlp_wrapper, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(f'Cross-validation accuracy: {cv_results.mean()}')\n",
    "\n",
    "# random search.\n",
    "random_search = RandomizedSearchCV(estimator=mlp_wrapper, param_distributions=param_dist, n_iter=121, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "print(f'Best parameters found: {best_params}')\n",
    "\n",
    "n_params = len(random_search.cv_results_['params'])\n",
    "top_n = min(27, n_params)\n",
    "top_n_indices = np.argsort(random_search.cv_results_['mean_test_score'])[-top_n:]\n",
    "top_n_params = [random_search.cv_results_['params'][i] for i in top_n_indices]\n",
    "\n",
    "# Print top 27 parameter sets.\n",
    "print(\"Top 27 parameter sets:\")\n",
    "for i, params in enumerate(top_n_params):\n",
    "    print(f\"Set {i+1}:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()\n",
    "\n",
    "# Save params.\n",
    "os.makedirs('../models/mlp-validation', exist_ok=True)\n",
    "with open('../models/mlp-validation/top_27_params.json', 'w') as f:\n",
    "    json.dump(top_n_params, f, indent=2)\n",
    "\n",
    "# Train ensemble.\n",
    "models = Parallel(n_jobs=-1)(delayed(MLPWrapper(input_size, output_size, **params).fit)(X_train, y_train) for params in top_n_params)\n",
    "\n",
    "# Export models.\n",
    "for i, (model, params) in enumerate(zip(models, top_n_params)):\n",
    "    torch.save(model.model.state_dict(), f'../models/mlp-validation/mlp_model_{i}.pth')\n",
    "    with open(f'../models/mlp-validation/mlp_params_{i}.json', 'w') as f:\n",
    "        json.dump(params, f, indent=2)\n",
    "\n",
    "def predict_model(model, data):\n",
    "    return model.predict_proba(data)\n",
    "\n",
    "all_preds = Parallel(n_jobs=-1)(delayed(predict_model)(model, X_val) for model in models)\n",
    "all_preds = np.array(all_preds)\n",
    "avg_preds = np.mean(all_preds, axis=0)\n",
    "final_predictions = np.argmax(avg_preds, axis=1)\n",
    "\n",
    "# Evaluate model ensemble.\n",
    "val_accuracy = accuracy_score(y_val, final_predictions)\n",
    "val_precision = precision_score(y_val, final_predictions, average='weighted')\n",
    "val_recall = recall_score(y_val, final_predictions, average='weighted')\n",
    "val_f1 = f1_score(y_val, final_predictions, average='weighted')\n",
    "val_roc_auc = roc_auc_score(y_val, avg_preds, multi_class='ovo')\n",
    "val_conf_matrix = confusion_matrix(y_val, final_predictions)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation Precision: {val_precision}')\n",
    "print(f'Validation Recall: {val_recall}')\n",
    "print(f'Validation F1 Score: {val_f1}')\n",
    "print(f'Validation ROC AUC Score: {val_roc_auc}')\n",
    "print(f'Confusion Matrix:\\n{val_conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model after validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both test and reload training data.\n",
    "X_train = pd.read_csv('../data/X_train_500.csv', low_memory=False)\n",
    "X_test = pd.read_csv('../data/X_test_500.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2831, 472)\n",
      "Test Accuracy: 0.8491699046273402\n",
      "Test Precision: 0.8396219412862628\n",
      "Test Recall: 0.8491699046273402\n",
      "Test F1 Score: 0.8419454059184215\n",
      "Test ROC AUC Score: 0.8651530377890234\n",
      "Confusion Matrix:\n",
      "[[1167   15  157]\n",
      " [  23   32   97]\n",
      " [ 102   33 1205]]\n"
     ]
    }
   ],
   "source": [
    "output_path = '../results/mlp-validation.csv'\n",
    "\n",
    "def soft_vote(preds):\n",
    "    summed_preds = np.sum(preds, axis=0)\n",
    "    return softmax(summed_preds, axis=1)\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "def drop_allnan(data):\n",
    "    for col in data.columns:\n",
    "        if data[col].isna().sum() == len(data):\n",
    "            data = data.drop(columns=col)\n",
    "    return data\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.hidden = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.hidden(x)\n",
    "\n",
    "X_train = drop_allnan(X_train)\n",
    "columns = X_train.columns.tolist()\n",
    "\n",
    "preprocessor = joblib.load('../models/mlp-validation/preprocessor.joblib')\n",
    "\n",
    "# Load models.\n",
    "models = []\n",
    "num_models = 27\n",
    "output_size = 3 \n",
    "\n",
    "for i in range(num_models):\n",
    "    with open(f'../models/mlp-validation/mlp_params_{i}.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "    \n",
    "    state_dict = torch.load(f'../models/mlp-validation/mlp_model_{i}.pth')\n",
    "    input_size = state_dict['hidden.0.weight'].shape[1]\n",
    "    \n",
    "    model = MLP(input_size, params['hidden_sizes'], output_size, params['dropout_rate'])\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "y_test = pd.read_csv('../data/y_test_id.csv', low_memory=False) \n",
    "impact_vals = {'LOW': 0, 'MODIFIER': 1, 'MODERATE': 1.5, 'HIGH': 2}\n",
    "encoded_impacts = [impact_vals[imp] for imp in X_test['IMPACT']]\n",
    "X_test = X_test.drop(columns=['IMPACT'])\n",
    "X_test['IMPACT'] = encoded_impacts\n",
    "X_test = X_test[columns]\n",
    "ids = X_test['ID'].tolist()\n",
    "X_test = X_test.drop(columns='ID')\n",
    "\n",
    "for col in X_test.columns:\n",
    "    X_test[col] = X_test[col].astype(X_train[col].dtype)\n",
    "\n",
    "X_test = utils.transform(X_test, preprocessor)\n",
    "\n",
    "# Convert to PyTorch tensor.\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "\n",
    "# Pool the predictions.\n",
    "all_preds = []\n",
    "for model in models:\n",
    "    with torch.no_grad():\n",
    "        preds = nn.functional.softmax(model(X_test_tensor), dim=1).numpy()\n",
    "    all_preds.append(preds)\n",
    "\n",
    "y_pred_proba = soft_vote(np.array(all_preds))\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Map the labels to numbers.\n",
    "label_mapping = {'Neutral': 0, 'GOF': 1, 'LOF': 2}\n",
    "y_test_numeric = [label_mapping[label] for label in y_test['label']]\n",
    "\n",
    "accuracy = accuracy_score(y_test_numeric, y_pred)\n",
    "precision = precision_score(y_test_numeric, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_numeric, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_numeric, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_numeric, y_pred_proba, multi_class='ovo')\n",
    "conf_matrix = confusion_matrix(y_test_numeric, y_pred)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(f'Test Precision: {precision}')\n",
    "print(f'Test Recall: {recall}')\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Test ROC AUC Score: {roc_auc}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "out = []\n",
    "for i in range(len(y_pred)):\n",
    "    out.append([ids[i], ['Neutral', 'GOF', 'LOF'][y_pred[i]], *y_pred_proba[i]])\n",
    "out = pd.DataFrame(out, columns=['ID', 'prediction', 'LoGoFunc_Neutral', 'LoGoFunc_GOF', 'LoGoFunc_LOF'])\n",
    "out.to_csv(output_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutation against y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision   recall  f1_score  \\\n",
      "0   0.84917   0.839622  0.84917  0.841945   \n",
      "\n",
      "                                   confusion_matrix  \n",
      "0  [[1167, 15, 157], [23, 32, 97], [102, 33, 1205]]  \n"
     ]
    }
   ],
   "source": [
    "# This is just to manually verify the test output.\n",
    "predictions_file = output_path\n",
    "\n",
    "# Load y_test.\n",
    "y_test_path = '../data/y_test_id.csv'\n",
    "y_test = pd.read_csv(y_test_path)\n",
    "y_true = y_test['label']\n",
    "\n",
    "# Encode labels to numbers.\n",
    "label_mapping = {'Neutral': 0, 'GOF': 1, 'LOF': 2}\n",
    "y_true_numeric = [label_mapping[label] for label in y_true]\n",
    "\n",
    "# Load predictions.\n",
    "predictions = pd.read_csv(predictions_file)\n",
    "\n",
    "# Ensure DataFrames have same number of rows.\n",
    "assert len(predictions) == len(y_test)\n",
    "\n",
    "# Align predictions and true labels by index\n",
    "y_pred = predictions['prediction']\n",
    "y_pred_numeric = [label_mapping[label] for label in y_pred]\n",
    "\n",
    "# Perform the evaluation using Scikit-learn's metrics.\n",
    "accuracy = accuracy_score(y_true_numeric, y_pred_numeric)\n",
    "precision = precision_score(y_true_numeric, y_pred_numeric, average='weighted')\n",
    "recall = recall_score(y_true_numeric, y_pred_numeric, average='weighted')\n",
    "f1 = f1_score(y_true_numeric, y_pred_numeric, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_true_numeric, y_pred_numeric)\n",
    "\n",
    "results = [{\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'confusion_matrix': conf_matrix.tolist() \n",
    "}]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(metrics_file, index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute micro/macro-REC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../metrics/mlp-evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = metrics_file\n",
    "output_file = f'../metrics/{model_type}-evaluation.csv'\n",
    "\n",
    "def macro(confusion_matrix):\n",
    "    cm = np.array(confusion_matrix)\n",
    "    recalls = np.diag(cm) / np.sum(cm, axis=1)\n",
    "    return np.mean(recalls)\n",
    "\n",
    "def micro(confusion_matrix):\n",
    "    cm = np.array(confusion_matrix)\n",
    "    true_positives = np.diag(cm)\n",
    "    total_true_positives = np.sum(true_positives)\n",
    "    total_actual_positives = np.sum(cm)\n",
    "    return total_true_positives / total_actual_positives\n",
    "\n",
    "with open(input_file, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    rows = list(reader)\n",
    "\n",
    "for row in rows:\n",
    "    confusion_matrix = ast.literal_eval(row['confusion_matrix'])\n",
    "    macro = macro(confusion_matrix)\n",
    "    micro_recall = micro(confusion_matrix)\n",
    "    row['micro_recall'] = f'{micro_recall:.4f}'\n",
    "    row['macro'] = f'{macro:.4f}'\n",
    "\n",
    "    # Remove the original 'weighted' REC column.\n",
    "    if 'recall' in row:\n",
    "        del row['recall']\n",
    "\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['accuracy', 'precision', 'f1_score', 'micro_recall', 'macro', 'confusion_matrix']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logofunc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
