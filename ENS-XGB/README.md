1. The `generate_subsets.ipynb` notebook uses the decoded rankings to generate train and test subsets, each containing the top "x" most important features, ranging from 1 to 499. These will be used by ENS-XGB and ENS-LGBM for training/testing. For ENS-XGB, this notebook subsequently encodes the feature names because otherwise XGBoost will terminate with an error.
2. `train.ipynb` iterates over all 499 of the subsets and trains each model ensemble. This takes over a day to run, so I used the `tqdm` package to provide a progress bar.
3. `test.ipynb` iterates over all 499 of the trained model ensembles and exports results to the `results` folder and the various performance metrics to the `metrics` folder.
4. `sort-metrics.ipynb` is just used for combining the individual metrics and reports into a new CSV. 
5. `graphs.ipynb` first computes macro-recall from the confusion matrices (I had originally used weighted recall, which gave the same values as ACC for every model). Then it plots overall performance metrics followed by class-wise performance metrics. I used PrettyTable to display data in a tabular format for ease of reading. 
6. `roc curves.ipynb` calculates AP score (I had originally just used PREC), performs the weighting/sensitivity analysis, arrives at optimal model (feature count), and then allows you to plot the ROC curves for that model. I. used PrettyTable again to display data in a tabular format.